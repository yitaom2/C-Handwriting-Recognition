{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.datasets import mnist \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Convolution2D, Dense, Flatten, MaxPooling2D\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test= x_test.reshape(10000, 28, 28, 1)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "for i in range(10000):\n",
    "    a = \"image/x_test/\" + str(i) + \".bmp\"\n",
    "    b = \"image/y_test/\" + str(i)\n",
    "#     np.savetxt(a, x_test[i,:,:,0])\n",
    "    np.savetxt(b, y_test[i])\n",
    "    cv2.imwrite(a, x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 03:37:34.344120 140436407048000 deprecation_wrapper.py:119] From /home/yitao/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0722 03:37:34.360091 140436407048000 deprecation_wrapper.py:119] From /home/yitao/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0722 03:37:34.362302 140436407048000 deprecation_wrapper.py:119] From /home/yitao/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0722 03:37:34.380993 140436407048000 deprecation_wrapper.py:119] From /home/yitao/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0722 03:37:34.477430 140436407048000 deprecation_wrapper.py:119] From /home/yitao/.local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0722 03:37:34.490435 140436407048000 deprecation_wrapper.py:119] From /home/yitao/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(16, (4, 4), padding=\"SAME\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2),padding='SAME'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=20, activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.9891 - acc: 0.6987\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.6048 - acc: 0.8226\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.4835 - acc: 0.8736\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.4136 - acc: 0.8936\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.3630 - acc: 0.9065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb9947a6c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 79us/step\n",
      "[0.3562602893076837, 0.9120000022649765]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_test, y_test, batch_size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/weights.h5') #保存权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_1/kernel:0' shape=(4, 4, 1, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(3136, 20) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(20,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(20, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     weights = layer.get_weights()\n",
    "#     if weights == []:\n",
    "#         continue\n",
    "        \n",
    "#     name = layer.get_config()['name']\n",
    "#     print(name)\n",
    "#     directory_name = \"layerData/\" + name \n",
    "#     if not os.path.isdir(directory_name):\n",
    "#         os.makedirs(directory_name)\n",
    "        \n",
    "#     if name.find('conv2d') != -1:\n",
    "#         layerNum = np.shape(layer.get_weights()[0])[3]\n",
    "#         imageNum = np.shape(layer.get_weights()[0])[2]\n",
    "        \n",
    "#         np.savetxt(directory_name + \"/bias\", weights[1])\n",
    "#         for j in range(imageNum):\n",
    "#             for i in range(layerNum):\n",
    "#                 sub_dir = directory_name + \"/imageNum\" + str(j)\n",
    "#                 if not os.path.isdir(sub_dir):\n",
    "#                     os.makedirs(sub_dir)\n",
    "#                 np.savetxt(sub_dir + \"/\" + str(i), weights[0][:,:,j,i])\n",
    "#     elif name.find('dense') != -1:\n",
    "#         np.savetxt(directory_name + \"/weight\", weights[0])\n",
    "#         np.savetxt(directory_name + \"/bias\", weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"layers.txt\", \"w\")\n",
    "for layer in model.layers:\n",
    "    temp = layer.get_config()\n",
    "    name = temp['name']\n",
    "    f.write(name)\n",
    "    weights = layer.get_weights()\n",
    "    \n",
    "    if name.find('flatten') != -1:\n",
    "        f.write(\" \" + str(layer.get_input_shape_at(0)[3]) + \",\" \n",
    "                + str(layer.get_input_shape_at(0)[1]) + \",\" \n",
    "                + str(layer.get_input_shape_at(0)[2])) #LayDim\n",
    "        f.write(\"\\n\")\n",
    "        continue\n",
    "        \n",
    "    if name.find('max_pooling2d') != -1:\n",
    "        f.write(\" \" + str(layer.get_input_shape_at(0)[3]) + \",\" \n",
    "                + str(layer.get_input_shape_at(0)[1]) + \",\" \n",
    "                + str(layer.get_input_shape_at(0)[2])) #LayDim\n",
    "        kernel_size = temp['pool_size']\n",
    "        f.write(\" \" + str(kernel_size[0]) + \",\" + str(kernel_size[1])) #maskDim\n",
    "        f.write(\" \" + str(temp['strides'][0])) #stride\n",
    "        f.write(\" \" + temp['padding'].upper()) #ZeroPadding\n",
    "        f.write(\"\\n\")\n",
    "        continue\n",
    "        \n",
    "    directory_name = \"layerData/\" + name \n",
    "    if not os.path.isdir(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "        \n",
    "    if name.find('conv2d') != -1:\n",
    "        f.write(\" \" + str(layer.get_input_shape_at(0)[3]) + \",\" \n",
    "                + str(layer.get_input_shape_at(0)[1]) + \",\" \n",
    "                + str(layer.get_input_shape_at(0)[2])) #LayDim\n",
    "        kernel_size = temp['kernel_size']\n",
    "        f.write(\" \" + str(temp['filters']) + \",\" + str(kernel_size[0]) + \",\" + str(kernel_size[1])) #maskDim\n",
    "        f.write(\" \" + str(temp['strides'][0])) #stride\n",
    "        f.write(\" \" + temp['padding'].upper()) #ZeroPadding\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        layerNum = np.shape(layer.get_weights()[0])[3]\n",
    "        imageNum = np.shape(layer.get_weights()[0])[2]\n",
    "        \n",
    "        np.savetxt(directory_name + \"/bias\", weights[1])\n",
    "        for j in range(imageNum):\n",
    "            for i in range(layerNum):\n",
    "                sub_dir = directory_name + \"/imageNum\" + str(j)\n",
    "                if not os.path.isdir(sub_dir):\n",
    "                    os.makedirs(sub_dir)\n",
    "                np.savetxt(sub_dir + \"/\" + str(i), weights[0][:,:,j,i])\n",
    "    elif name.find('dense') != -1:\n",
    "        f.write(\" \" + str(layer.get_input_shape_at(0)[1]))\n",
    "        f.write(\" \" + str(layer.get_output_shape_at(0)[1]))\n",
    "        f.write(\" \" + str(layer.get_config()['activation']))\n",
    "        f.write(\"\\n\")\n",
    "        np.savetxt(directory_name + \"/weight\", weights[0])\n",
    "        np.savetxt(directory_name + \"/bias\", weights[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
